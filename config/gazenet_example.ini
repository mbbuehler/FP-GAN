; This file contains configurations based on the SIMPLISTIC Gazenet
; - small image size (36x60)
; - b/w images

[DEFAULT]
; batch size when training
batch_size = 128
; batch size for testing
batch_size_inference = 100
; Image dimensions. Input will be scaled accordingly
image_height = 36
image_width = 60
; batch or instance
norm = batch
; If true we use color images, otherwise gray-scale
rgb = False
learning_rate = 2e-4
; If true we train the network with L2 regularisation
use_regulariser = False
regularisation_lambda = 1e-4
; Adam first and second moment decay rate
beta1 = 0.9
beta2 = 0.999
; Path to training set
path_train =
; Path to validation set (should be the same kind of dataset as training set)
path_validation_within =
; Path to test set. May be empty.
path_test =
; Paths to UnityEyes and MPIIFaceGaze test sets. Maybe be empty.
path_validation_unity = 
path_validation_mpii =
; Number of steps to train the model
n_steps = 100000
; If you want to restart training, you can give the path to the
; checkpoint folder here. If this string is empty, a new model will be trained.
checkpoint_folder =
; This is the scope where all tensors will be created
model_name = gazenet
model_name_pb = %(model_name)s.pb

; Give the dataset classes, e.g. unity.
; Please refer to util.enum_classes.DatasetClass for allowed values.
dataset_class_train =
dataset_class_validation_unity = unity
dataset_class_validation_mpii = mpii
dataset_class_test =

; Normalise gaze direction from [-pi, pi] to [-1,1]
normalise_gaze = False
; Filter out samples where the gaze direction is unrealistic (only applies to
; UnityEyes).
filter_gaze = False
; Whether to apply augmentation for training
augmentation = True
