; Sample config file for the FP-GAN.
; It contains configurations for the FP-GAN using
; combined losses for eye gaze, landmarks and identity transform

[DEFAULT]
; batch size when training
batch_size = 8
; batch size when translating pictures
batch_size_inference = 100
; image dimensions (images will be scaled accordingly)
image_height = 36
image_width = 60
; If true a least squares loss is applied instead of cross-entropy (default: true)
use_lsgan = true
; instance or batch norm (default: instance)
norm = instance
; If true we use color images, otherwise gray-scale
rgb = False
; Weight for forward cycle loss (S->R'->S')
lambda1 = 10
; Weight for backward cycle loss (R->S'->R')
lambda2 = 10
; Weight for identity transform loss
lambda_identity = 2
; Weight for eye gaze consistency loss
lambda_gaze = 25
; Weight for landmarks consistency loss
lambda_landmarks = 0
; Learning rate for FP-GAN
learning_rate = 2e-4
; Adam first moment decay rate
beta1 = 0.5
; We update the discriminator with a pool of images. This is the pool size.
pool_size = 50
; Number of filters in the first layer of the generators.
ngf = 64
; Path to the synthetic dataset (UnityEyes). Should point to a folder.
S = ../data/UnityEyes/
; Path to the MPIIFaceGaze dataset. Should be an h5 file.
R = ../data/MPIIFaceGaze/single-eye-right_zhang.h5
; Number of steps to train the FP-GAN.
n_steps = 150000
; If you want to restart training, you can give the path to the
; checkpoint folder here. If this string is empty, a new model will be trained.
checkpoint_folder = ""
; Normalise gaze direction from [-pi, pi] to [-1,1]
normalise_gaze = False
; Filter out samples where the gaze direction is unrealistic (only applies to
; UnityEyes.
filter_gaze = False

; Name for the exported models (used for image translation)
model_name_s2r = Unity2MPII.pb
model_name_r2s = MPII2Unity.pb

; Choose whatever name you like
gan_name = fpgan
; Name for eye gaze predictor network for feature estimation
ege_name = gazenet_u_augmented_bw
; Path to pre-trained eye gaze estimator network.
ege_path = ../models/checkpoints_gazenet/20190107-1032_gazenet_u_augmented_bw/
; batch or instance
ege_norm = batch
; Path to pre-trained landmarks detector
lm_path = ../models/outputs_elg/ELG_i120x72_f60x36_n64_m3/checkpoints/hourglass/model-1295134
; Whether to save generated images during training (in tensorboard)
track_images = True
; Whether to save summary histograms during training (in tensorboard)
track_histograms = True

[LIGHT]
; The LIGHT configuration keeps the memory lower by not generating as many
; tensorboard summaries. This allows for a larger batch size.
track_images = False
track_histograms = False
batch_size = 64
gan_name = light
learning_rate = 5e-5
n_steps = 15000000




